---
title: "Lab 07: What makes a song more positive?"
author: "The A Team: Naomi Rubin, Jwalin Patel, Annie Sawers, Alex Williams, JM Stroh"
date: "3-23-21"
output: 
  pdf_document: 
    fig_height: 4
    fig_width: 6
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo  =  TRUE,
                      warning = FALSE, 
                      message = FALSE)
```

## Load packages & data

```{r load-packages, message = FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(rms)
```

```{r load-data, message = FALSE}
spotify <- read_csv("data/spotify-popular.csv") %>%
  mutate(key = factor(key), 
         mode = factor(mode))
```

## Exercise 1

```{r}
full_model <- lm(valence ~ danceability + energy + key + loudness +
                   mode + speechiness + acousticness + instrumentalness +
                   liveness + tempo + duration_ms + playlist_genre,
                 data=spotify)

tidy(full_model)%>%
  kable(digits = 3)
```

```{r}
int_only_model <- lm(valence ~ 1, data = spotify)
tidy(int_only_model)%>%
  kable(digits=3)
```


## Exercise 2

```{r results = "hide"}
backward_aic <- step(full_model, direction="backward")
```

```{r}
tidy(backward_aic)%>%
  kable(digits=3)
```

## Exercise 3

```{r}
## number of observations
n <- nrow(spotify)
```


```{r results = "hide"}
backward_bic <- step(full_model, direction="backward", k=log(n))
```

```{r}
tidy(backward_bic)%>%
  kable(digits=3)
```

## Exercise 4

The models do not have the same number of predictors. The model using AIC has 
all of the same predictors as the model using BIC plus an additional five 
predictor variables.

This is the model we would expect to have more predictors because for data with 
more than eight observations, like the spotify data which has 508 observations,
the penalty for BIC is larger than that of AIC. This means that BIC tends to 
favor more parsimonious models (i.e. models with fewer terms). Therefore, we 
would expect the model using BIC to have fewer predictors, and this is in fact 
the case.

